#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
头像匹配器类
专门处理头像表情分析和匹配
"""

import re
import os
import random
from typing import Dict, List, Optional, Callable
from .base_matcher import BaseMatcher
from PIL import Image
from sentence_transformers import SentenceTransformer, util
try:
    from transformers import CLIPTokenizerFast as CLIPTokenizerClass
except Exception:
    try:
        from transformers import CLIPTokenizer as CLIPTokenizerClass
    except Exception:
        CLIPTokenizerClass = None


class HeadMatcher(BaseMatcher):
    """头像匹配器类"""
    
    def __init__(self):
        """初始化头像匹配器"""
        super().__init__()
        self.dimensions = ["眼睛形状", "嘴型", "表情", "脸部动态", "情感强度"]
        # 已移除Excel加载，统一改为基于文件夹的匹配
        self.clip_model: Optional[SentenceTransformer] = None
        self._clip_tokenizer = None
    
    def analyze_user_requirement(self, requirement: str) -> Dict[str, str]:
        """分析用户需求，提取五个维度的特征"""
        try:
            prompt = (
                f"将\"{requirement}\"按照\"眼睛形状、嘴型、表情、脸部动态、情感强度\"五个维度进行分析，精简得到的结果，并将结果按照以下形式输出：\n"
                "眼睛形状：\n"
                "嘴型：\n"
                "表情：\n"
                "脸部动态：\n"
                "情感强度：\n"
            )
            system_prompt = "你是一个专业的需求分析专家。请根据用户的需求描述，分析出对应的视觉特征。"
            analysis_text = self._call_ai(system_prompt, prompt, temperature=0.3, max_tokens=500)
            if analysis_text:
                return self._parse_requirement_analysis(analysis_text)
            return {dim: "未识别" for dim in self.dimensions}
        
        except Exception as e:
            print(f"分析用户需求失败: {str(e)}")
            return {dim: "未识别" for dim in self.dimensions}
    
    def _parse_requirement_analysis(self, analysis_text: str) -> Dict[str, str]:
        """解析需求分析结果"""
        result = {dim: "" for dim in self.dimensions}
        
        patterns = {
            "眼睛形状": r"眼睛形状[：:]\s*([^\n]+)",
            "嘴型": r"嘴型[：:]\s*([^\n]+)",
            "表情": r"表情[：:]\s*([^\n]+)",
            "脸部动态": r"脸部动态[：:]\s*([^\n]+)",
            "情感强度": r"情感强度[：:]\s*([^\n]+)"
        }
        
        for key, pattern in patterns.items():
            match = re.search(pattern, analysis_text)
            if match:
                result[key] = match.group(1).strip()
            else:
                result[key] = "未识别"
        
        return result
    
    def find_best_matches(self, requirement: str, top_k: int = 3, log_callback: Optional[Callable[[str], None]] = None) -> tuple:
        """找到最匹配的头像图片，返回结果和处理日志；支持日志回调实时输出"""
        if self.df.empty:
            return [], []
        
        # 初始化日志收集
        processing_logs = []
        
        # 分析用户需求
        requirement_features = self.analyze_user_requirement(requirement)
        log_msg = f"头像需求分析结果: {requirement_features}"
        print(log_msg)
        processing_logs.append(log_msg)
        if log_callback:
            log_callback(log_msg)
        
        # 计算每张图片的匹配得分
        scores = []
        processing_logs.append("开始计算头像图片匹配得分...")
        if log_callback:
            log_callback("开始计算头像图片匹配得分...")
        
        for index, row in self.df.iterrows():
            image_features = {dim: str(row.get(dim, '')) for dim in self.dimensions}
            
            dimension_scores = self.calculate_dimension_scores(
                requirement_features, image_features, self.dimensions
            )
            
            # 计算综合得分（五个维度的平均分）
            total_score = sum(dimension_scores.values()) / len(dimension_scores)
            
            # 从Excel中获取图片路径
            image_name = str(row.get('图片名', ''))
            image_path = str(row.get('图片url地址', ''))
            
            # 如果Excel中没有路径，则使用默认路径
            if not image_path or image_path == 'nan':
                image_path = f"data/joy_head/{image_name}"
            
            scores.append({
                "image_name": image_name,
                "image_path": image_path,
                "score": total_score,
                "dimension_scores": dimension_scores,
                "features": image_features,
                "requirement_features": requirement_features,
                "type": "head"
            })
            
            log_msg = f"头像图片 {image_name} 综合得分: {total_score:.1f}, 维度得分: {dimension_scores}"
            print(log_msg)
            processing_logs.append(log_msg)
            if log_callback:
                log_callback(log_msg)
        
        # 按得分排序，返回前top_k个
        scores.sort(key=lambda x: x['score'], reverse=True)
        processing_logs.append(f"头像匹配完成，选择前{top_k}个最佳匹配")
        if log_callback:
            log_callback(f"头像匹配完成，选择前{top_k}个最佳匹配")
        
        return scores[:top_k], processing_logs
    
    def find_best_matches_from_folder(self, requirement: str, folder_path: str, 
                                     top_k: int = 2, log_callback: Optional[Callable[[str], None]] = None) -> tuple:
        """从指定文件夹中找到最匹配的头像图片"""
        import glob
        
        # 初始化日志收集
        processing_logs = []
        
        # 获取文件夹中的所有图片文件
        image_extensions = ['*.png', '*.jpg', '*.jpeg', '*.bmp', '*.gif']
        all_images = []
        
        for extension in image_extensions:
            all_images.extend(glob.glob(os.path.join(folder_path, extension)))
        
        if not all_images:
            log_msg = f"警告：在文件夹 {folder_path} 中没有找到图片文件"
            print(log_msg)
            processing_logs.append(log_msg)
            if log_callback:
                log_callback(log_msg)
            return [], processing_logs
        
        # 使用 CLIP 对“表情”文本与图片进行相似度检索
        requirement_features = self.analyze_user_requirement(requirement)
        expr_text = self._extract_expression_text(requirement)
        if not expr_text:
            expr_text = requirement_features.get('表情', '') or requirement
        print(f"头像CLIP检索文本: {expr_text}")
        log_msg = f"头像需求分析结果: {requirement_features}"
        print(log_msg)
        processing_logs.append(log_msg)
        if log_callback:
            log_callback(log_msg)

        processing_logs.append(f"开始计算文件夹 {folder_path} 中头像图片匹配得分（CLIP检索）...")
        if log_callback:
            log_callback(f"开始计算文件夹 {folder_path} 中头像图片匹配得分（CLIP检索）...")

        # 懒加载 CLIP 模型
        self._ensure_clip_model()

        # 文本嵌入（确保不超过 CLIP 最大序列长度 77）
        try:
            # 先用 CLIP 分词器安全截断，避免 77/82 等长度冲突
            expr_text_safe = self._truncate_clip_text(expr_text)
            # SentenceTransformer.encode 文本参数为位置参数或 sentences 关键字
            text_emb = self.clip_model.encode([expr_text_safe], convert_to_tensor=True, normalize_embeddings=True)
        except Exception as e:
            err = f"文本向量化失败: {str(e)}"
            print(err)
            processing_logs.append(err)
            if log_callback:
                log_callback(err)
            return [], processing_logs

        # 图片检索评分
        scores = []
        for img_path in all_images:
            img_name = os.path.basename(img_path)
            try:
                image = Image.open(img_path).convert('RGB')
                # SentenceTransformer.encode 图片参数为位置参数（传入 PIL.Image 列表）
                img_emb = self.clip_model.encode([image], convert_to_tensor=True, normalize_embeddings=True)
                sim = util.cos_sim(img_emb, text_emb)[0][0].item()
                total_score = float(sim)
            except Exception as e:
                total_score = 0.0
                err = f"图片向量化失败 {img_name}: {str(e)}"
                print(err)
                processing_logs.append(err)
                if log_callback:
                    log_callback(err)

            scores.append({
                "image_name": img_name,
                "image_path": img_path,
                "score": total_score,
                "dimension_scores": {dim: total_score for dim in self.dimensions},
                "features": {dim: "CLIP相似度" for dim in self.dimensions},
                "requirement_features": requirement_features,
                "type": "head"
            })

            log_msg = f"头像图片 {img_name} 相似度: {total_score:.4f}"
            print(log_msg)
            processing_logs.append(log_msg)
            if log_callback:
                log_callback(log_msg)
        
        # 按得分排序并去重，返回前top_k个
        scores.sort(key=lambda x: x['score'], reverse=True)
        unique = []
        seen = set()
        for item in scores:
            p = item.get('image_path')
            if p and p not in seen:
                unique.append(item)
                seen.add(p)
            if len(unique) >= top_k:
                break
        names = [u.get('image_name') for u in unique]
        processing_logs.append(f"头像匹配完成，选择前{top_k}个最佳匹配: {names}")
        if log_callback:
            log_callback(f"头像匹配完成，选择前{top_k}个最佳匹配: {names}")
        
        return unique, processing_logs

    def find_one_best_match_from_folder(self, requirement: str, folder_path: str,
                                        top_k: int = 5, log_callback: Optional[Callable[[str], None]] = None) -> tuple:
        """从文件夹中找到前top_k排序，并从中随机抽取一张返回"""
        top_results, logs = self.find_best_matches_from_folder(requirement, folder_path, top_k=top_k, log_callback=log_callback)
        if not top_results:
            return [], logs
        chosen = random.choice(top_results)
        choose_log = f"从前{top_k}名中随机抽取的图片: {chosen.get('image_name')}"
        print(choose_log)
        logs.append(choose_log)
        if log_callback:
            log_callback(choose_log)
        return [chosen], logs

    def _ensure_clip_model(self):
        """懒加载并缓存 CLIP 文本/图片编码模型"""
        if self.clip_model is None:
            self.clip_model = SentenceTransformer('clip-ViT-B-32')
            # 尝试设置最大序列长度（部分后端可能不生效，但设置以示约束）
            if hasattr(self.clip_model, 'max_seq_length'):
                try:
                    self.clip_model.max_seq_length = 77
                except Exception:
                    pass

    def _ensure_clip_tokenizer(self):
        """懒加载 CLIP 分词器用于安全截断文本到 77 tokens。"""
        if self._clip_tokenizer is None and CLIPTokenizerClass is not None:
            try:
                self._clip_tokenizer = CLIPTokenizerClass.from_pretrained('openai/clip-vit-base-patch32')
            except Exception:
                # 兜底：无法加载则保持 None
                self._clip_tokenizer = None

    def _truncate_clip_text(self, text: str) -> str:
        """将文本安全截断到 CLIP 支持的最大 token 长度（默认 77）。
        若分词器不可用，则返回原始文本。"""
        try:
            self._ensure_clip_tokenizer()
            if self._clip_tokenizer is None:
                return text
            max_len = 77
            encoded = self._clip_tokenizer(text, truncation=True, max_length=max_len, return_tensors=None)
            ids = encoded.get('input_ids')
            if isinstance(ids, list) and len(ids) > 0:
                first = ids[0] if isinstance(ids[0], list) else ids
                truncated_text = self._clip_tokenizer.decode(first, skip_special_tokens=True)
                # 打印一次有帮助的日志
                try:
                    original_ids = self._clip_tokenizer(text).get('input_ids', [])
                    original_len = len(original_ids[0] if original_ids and isinstance(original_ids[0], list) else original_ids)
                    truncated_len = len(first)
                    if original_len > truncated_len:
                        print(f"CLIP文本已截断: 原tokens={original_len} -> 截断后={truncated_len}")
                except Exception:
                    pass
                return truncated_text.strip()
            return text
        except Exception:
            return text

    def _extract_expression_text(self, requirement: str) -> str:
        try:
            m = re.search(r"表情[：:]\s*([^\n]+)", requirement)
            if m:
                return m.group(1).strip()
            keywords = [
                "大笑","微笑","开心","愉快","高兴","喜悦",
                "愤怒","生气","怒视",
                "悲伤","难过","哭泣",
                "惊讶","震惊",
                "害羞","脸红",
                "冷漠","面瘫",
                "张嘴","咧嘴","闭嘴",
                "眨眼","闭眼"
            ]
            for kw in keywords:
                if kw in requirement:
                    return kw
            return ""
        except Exception:
            return ""
